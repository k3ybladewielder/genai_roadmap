# Generative AI Applications Roadpmap üóùÔ∏è
## O que s√£o modelos generativos
Modelos generativos s√£o uma classe de algoritmos em aprendizado de m√°quina que aprendem a gerar **novas** amostras de dados que s√£o semelhantes √†s amostras de treinamento. Eles tentam modelar a distribui√ß√£o dos dados reais para criar novos exemplos que seguem a mesma distribui√ß√£o.

### Aprendizado de M√°quina vs Modelos Generativos

O Modelos tradicionais de ML geralmente t√™m como objetivo **prever** r√≥tulos de classe ou valores cont√≠nuos com base em dados de entrada. Eles se concentram em **aprender a rela√ß√£o entre as caracter√≠sticas dos dados e as sa√≠das desejadas**. A maioria dos modelos tradicionais √© treinada usando **dados rotulados**, onde o modelo aprende a partir de exemplos com entradas e sa√≠das conhecidas. Alguns exemplos s√£o **Regress√£o Linear, M√°quinas de Vetores de Suporte (SVM), Redes Neurais Feedforward, √Årvores de Decis√£o, K-Nearest Neighbors (KNN)**, etc. Os modelos tradicionais s√£o **treinados para minimizar a diferen√ßa (erro)** entre as previs√µes do modelo e os valores reais nos dados de treinamento (por exemplo, minimizando a perda). Estes modelos s√£o projetados para fazer previs√µes ou classifica√ß√µes com base nos dados reais e n√£o geram novos dados.

Os **modelos de intelig√™ncia artificial generativa ("Gen AI")** s√£o projetados para **gerar novos dados** que imitam a distribui√ß√£o dos dados de treinamento. Eles n√£o se concentram em **prever ou classificar**, mas em criar novas amostras realistas. Muitos modelos Gen AI s√£o treinados usando **t√©cnicas n√£o supervisionadas ou semi-supervisionadas**, onde n√£o √© necess√°rio que os dados de treinamento sejam rotulados. Exemplos incluem **Redes Adversariais Generativas (GANs), Modelos de Difus√£o, Modelos Autoregressivos (como GPT), Autoencoders Variacionais (VAEs)**, etc. Esses modelos **tentam aprender a distribui√ß√£o dos dados** subjacente para gerar novas amostras semelhantes √†s do conjunto de treinamento. Eles utilizam m√©todos como **adversaria√ß√£o (em GANs)** ou **otimiza√ß√£o da fun√ß√£o de perda baseada na gera√ß√£o de dados (em VAEs)**. Em vez de simplesmente **fazer previs√µes**, os modelos Gen AI podem **gerar novos textos, imagens, m√∫sicas ou outros tipos de dados** a partir de uma distribui√ß√£o aprendida.

Saiba mais em:
- [AI, Machine Learning, Deep Learning and Generative AI Explained](https://www.youtube.com/watch?v=qYNweeDHiyU)
- [How Large Language Models Work](https://www.youtube.com/watch?v=5sLYAQS9sWQ)
- [What are Large Language Models (LLMs)?](https://www.youtube.com/watch?v=iR2O2GPbB0E&t=1s&pp=ygULd2hhdCBpcyBsbG0%3D)

## Cursos (6 horas)
- [Understanding and Applying Text Embeddings](https://www.deeplearning.ai/short-courses/google-cloud-vertex-ai/)
- [Open Source Models with Hugging Face](https://www.deeplearning.ai/short-courses/open-source-models-hugging-face/)
- [LangChain for LLM Application Development](https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/)
- [Building Generative AI Applications with Gradio](https://www.deeplearning.ai/short-courses/building-generative-ai-applications-with-gradio/)
- [Vector Databases: from Embeddings to Applications](https://www.deeplearning.ai/short-courses/vector-databases-embeddings-applications/)
- [Functions, Tools and Agents with LangChain](https://www.deeplearning.ai/short-courses/functions-tools-agents-langchain/)

## Resources üß∞
- [LLM Course](https://github.com/mlabonne/llm-course)
- [Hands-on LLMs Course](https://github.com/iusztinpaul/hands-on-llms?tab=readme-ov-file#hands-on-llms-course-)
- [The Full Stack LLM Bootcamp](https://fullstackdeeplearning.com/)
- [Prompt Engineering Guide](https://www.promptingguide.ai/)
- [VectorHub](https://hub.superlinked.com/)
- Datacamp Spacy Cheatsheet [(blog post)](https://www.datacamp.com/cheat-sheet/spacy-cheat-sheet-advanced-nlp-in-python) and [(pdf)](spacy_cheatsheet.pdf)
